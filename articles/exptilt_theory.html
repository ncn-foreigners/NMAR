<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Exponential Tilting Theory ‚Ä¢ NMAR</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="‚Äùimage/svg+xml‚Äù" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Exponential Tilting Theory">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">NMAR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Tutorials</h6></li>
    <li><a class="dropdown-item" href="../articles/tutorial_empirical_likelihood.html">Empirical Likelihood</a></li>
    <li><a class="dropdown-item" href="../articles/tutorial_exptilt.html">Exponential Tilting</a></li>
    <li><a class="dropdown-item" href="../articles/tutorial_exptilt_nonparam.html">Exponential Tilting (Nonparametric)</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Theory</h6></li>
    <li><a class="dropdown-item" href="../articles/el_empirical_likelihood_theory.html">Empirical Likelihood Theory for NMAR</a></li>
    <li><a class="dropdown-item" href="../articles/exptilt_theory.html">Exponential Tilting Theory</a></li>
    <li><a class="dropdown-item" href="../articles/exptilt_nonparam_theory.html">Nonparametric Exponential Tilting Theory</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/index.html">More articles...</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ncn-foreigners/NMAR/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Exponential Tilting Theory</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ncn-foreigners/NMAR/blob/package-dev/vignettes/exptilt_theory.Rmd" class="external-link"><code>vignettes/exptilt_theory.Rmd</code></a></small>
      <div class="d-none name"><code>exptilt_theory.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<p>This vignette explains the matrix-vectorized implementation of the
exponential tilting (EXPTILT) estimator used in this package. The
exposition focuses on concepts and linear-algebraic operations used in
the implementation (functions such as
<code>generate_conditional_density_matrix</code>,
<code>generate_C_matrix</code>, <code>generate_Odds</code>, and the
vectorized <code>s_function</code>), and mirrors the statistical
equations that underlie the algorithm (see Riddles et al.¬†(2016) for the
theoretical background).</p>
<p>The method operates on a dataset split into respondents and
non-respondents. Let
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><msub><mi>n</mi><mn>0</mn></msub><mo>+</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n = n_0 + n_1</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>1</mn></msub><annotation encoding="application/x-tex">n_1</annotation></semantics></math>
is the number of respondents (observed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>)
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>0</mn></msub><annotation encoding="application/x-tex">n_0</annotation></semantics></math>
is the number of non-respondents (missing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>).
The algorithm always treats these two groups separately: the
conditional-density model is fit on respondents and used to impute
support for non-respondents; the missingness model is fit using
covariates that include the candidate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
values.</p>
<p>We emphasize two distinct and disjoint sets of covariates throughout,
and we require they have empty intersection:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ùí≥</mi><mtext mathvariant="normal">outcome</mtext></msub><mo>‚à©</mo><msub><mi>ùí≥</mi><mtext mathvariant="normal">missingness</mtext></msub><mo>=</mo><mi>‚åÄ</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">\mathcal{X}_{\text{outcome}} \cap \mathcal{X}_{\text{missingness}} = \varnothing.</annotation></semantics></math></p>
<ul>
<li>covariates_for_outcome (denote
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mtext mathvariant="normal">out</mtext></msub><annotation encoding="application/x-tex">X_{\text{out}}</annotation></semantics></math>):
variables used to model the conditional density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>‚à£</mo><msub><mi>X</mi><mtext mathvariant="normal">out</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_1(y\mid X_{\text{out}})</annotation></semantics></math>
on respondents;</li>
<li>covariates_for_missingness (denote
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mtext mathvariant="normal">miss</mtext></msub><annotation encoding="application/x-tex">X_{\text{miss}}</annotation></semantics></math>):
variables used in the response probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mtext mathvariant="normal">miss</mtext></msub><mo>,</mo><mi>y</mi><mo>;</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(X_{\text{miss}},y;\phi)</annotation></semantics></math>
(this includes candidate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
values when evaluating the missing-data expectation).</li>
</ul>
<p>Distinguishing these sets clearly in notation and code is crucial:
the conditional density model is fit using
<code>covariates_for_outcome</code> on respondents only, while the
missingness model uses <code>covariates_for_missingness</code> and
(importantly) takes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
as an additional predictor when forming
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚ãÖ</mo><mo>;</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(\cdot;\phi)</annotation></semantics></math>.</p>
</div>
<div class="section level2">
<h2 id="notation-and-main-objects">Notation and main objects<a class="anchor" aria-label="anchor" href="#notation-and-main-objects"></a>
</h2>
<p>Let:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
be the total number of units; split them into respondents (observed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>)
and non-respondents (missing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>).
Denote indices with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
for non-respondents and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
(or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>)
for respondent outcomes used as support.</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>y</mi><mi>j</mi></msub><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>1</mn></msub></msubsup></mrow><annotation encoding="application/x-tex">\{y_j\}_{j=1}^{n_1}</annotation></semantics></math>
be the vector of observed outcome values (respondents).</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mtext mathvariant="normal">out</mtext></msup><annotation encoding="application/x-tex">X^{\text{out}}</annotation></semantics></math>
denote the matrix of covariates_for_outcome for respondents.</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mtext mathvariant="normal">un</mtext></msup><annotation encoding="application/x-tex">X^{\text{un}}</annotation></semantics></math>
denote the matrix of covariates_for_outcome for non-respondents.</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mtext mathvariant="normal">miss,obs</mtext></msup><annotation encoding="application/x-tex">X^{\text{miss,obs}}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mtext mathvariant="normal">miss,un</mtext></msup><annotation encoding="application/x-tex">X^{\text{miss,un}}</annotation></semantics></math>
denote the covariates_for_missingness for respondents and
non-respondents, respectively (we shorten these to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>X</mi><mtext mathvariant="normal">miss</mtext><mtext mathvariant="normal">obs</mtext></msubsup><annotation encoding="application/x-tex">X_{\text{miss}}^{\text{obs}}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>X</mi><mtext mathvariant="normal">miss</mtext><mtext mathvariant="normal">un</mtext></msubsup><annotation encoding="application/x-tex">X_{\text{miss}}^{\text{un}}</annotation></semantics></math>
when needed).</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mtext mathvariant="normal">miss</mtext></msub><mo>,</mo><mi>y</mi><mo>;</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(x_{\text{miss}},y;\phi)</annotation></semantics></math>
the response probability (no explicit link notation here): for a given
covariate row used in the missingness model and a candidate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚ãÖ</mo><mo>;</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(\cdot;\phi)</annotation></semantics></math>
denotes the probability of response under parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>.</li>
</ul>
<p>We build three central matrices:</p>
<ol style="list-style-type: decimal">
<li>
<p>Conditional-density matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>
(denoted in code as <code>f_matrix_nieobs</code>):</p>
<ul>
<li>Size:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0 \times n_1</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>0</mn></msub><annotation encoding="application/x-tex">n_0</annotation></semantics></math>
is the number of non-respondents and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>1</mn></msub><annotation encoding="application/x-tex">n_1</annotation></semantics></math>
is the number of distinct respondent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
values used as support.</li>
<li>Entries:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>‚à£</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">un</mtext></msubsup><mo>;</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">F_{ij} = f_1(y_j \mid x^{\text{un}}_i; \hat\gamma)</annotation></semantics></math><br>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\gamma</annotation></semantics></math>
is the (estimated) parameter vector of the conditional-density model fit
on respondents. This corresponds to the empirical approximation in
equation (12):
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>f</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àù</mo><munder><mo>‚àë</mo><mrow><mi>k</mi><mo>:</mo><mspace width="0.167em"></mspace><msub><mi>Œ¥</mi><mi>k</mi></msub><mo>=</mo><mn>1</mn></mrow></munder><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>‚à£</mo><msub><mi>x</mi><mi>k</mi></msub><mo>;</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">\hat f_1(y_j) \propto \sum_{k:\,\delta_k=1} f_1(y_j \mid x_k; \hat\gamma).</annotation></semantics></math>
</li>
</ul>
</li>
<li>
<p>Column-normalizer vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
(denoted in code as <code>C_matrix_nieobs</code>):</p>
<ul>
<li>Size:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>√ó</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n_1 \times 1</annotation></semantics></math>
(a column vector).</li>
<li>Entries: the column-sums of the conditional densities evaluated at
respondent covariates:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>j</mi></msub><mo>=</mo><mi>C</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>;</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><mo>‚àë</mo><mrow><mi>k</mi><mo>:</mo><mspace width="0.167em"></mspace><msub><mi>Œ¥</mi><mi>k</mi></msub><mo>=</mo><mn>1</mn></mrow></munder><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>‚à£</mo><msubsup><mi>x</mi><mi>k</mi><mtext mathvariant="normal">obs</mtext></msubsup><mo>;</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">C_j = C(y_j;\hat\gamma) = \sum_{k:\,\delta_k=1} f_1(y_j \mid x^{\text{obs}}_k;\hat\gamma).</annotation></semantics></math>
Conceptually this is the denominator that appears when fractional
weights are formed (see below).</li>
</ul>
</li>
<li>
<p>Odds matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(\phi)</annotation></semantics></math>
(constructed by <code>generate_Odds</code>):</p>
<ul>
<li>Size:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0 \times n_1</annotation></semantics></math>.</li>
</ul>
</li>
</ol>
<ul>
<li>Entries (for non-respondent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
and candidate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>j</mi></msub><annotation encoding="application/x-tex">y_j</annotation></semantics></math>):
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mn>1</mn><mo>‚àí</mo><mi>œÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">miss,un</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo>;</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>œÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">miss,un</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo>;</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">O_{ij}(\phi) = \frac{1-\pi(x^{\text{miss,un}}_i, y_j;\phi)}{\pi(x^{\text{miss,un}}_i, y_j;\phi)}</annotation></semantics></math>
The implementation exploits the separability of the linear predictor in
the parameters:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∑</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>Œ≤</mi><mn>0</mn></msub><mo>+</mo><msubsup><mi>X</mi><mi>i</mi><mtext mathvariant="normal">miss,un</mtext></msubsup><msub><mi>Œ≤</mi><mtext mathvariant="normal">miss</mtext></msub><mo>+</mo><msub><mi>Œ≤</mi><mi>y</mi></msub><msub><mi>y</mi><mi>j</mi></msub><mo>,</mo></mrow><annotation encoding="application/x-tex">\eta_{ij} = \beta_0 + X^{\text{miss,un}}_i\beta_{\text{miss}} + \beta_y y_j,</annotation></semantics></math>
and uses <code><a href="https://rdrr.io/r/base/outer.html" class="external-link">outer()</a></code> to form the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0\times n_1</annotation></semantics></math>
matrix efficiently.</li>
</ul>
<p>Using these objects we form a non-normalized weight matrix
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚ãÖ</mo><msub><mi>F</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">U_{ij}(\phi) = O_{ij}(\phi) \cdot F_{ij}</annotation></semantics></math>
and then a normalized fractional-weight matrix
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi>U</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><msub><mi>C</mi><mi>j</mi></msub></mfrac><mo>=</mo><mfrac><mrow><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>‚à£</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">un</mtext></msubsup><mo>;</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><munder><mo>‚àë</mo><mrow><mi>k</mi><mo>:</mo><mspace width="0.167em"></mspace><msub><mi>Œ¥</mi><mi>k</mi></msub><mo>=</mo><mn>1</mn></mrow></munder><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>‚à£</mo><msubsup><mi>x</mi><mi>k</mi><mtext mathvariant="normal">obs</mtext></msubsup><mo>;</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">W_{ij}(\phi) = \frac{U_{ij}(\phi)}{C_j} = \frac{O_{ij}(\phi)\,f_1(y_j\mid x^{\text{un}}_i;\hat\gamma)}{\sum_{k:\,\delta_k=1} f_1(y_j\mid x^{\text{obs}}_k;\hat\gamma)}.</annotation></semantics></math></p>
<p>These
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">W_{ij}</annotation></semantics></math>
match the weights appearing in the theoretical mean score approximation
(equation (15) in the notes): they are the fractional contribution of
each imputed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math>
pair to the conditional expectation for unit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>.</p>
</div>
<div class="section level2">
<h2 id="the-vectorized-score-s_2-and-matrix-algebra">The vectorized score S_2 and matrix algebra<a class="anchor" aria-label="anchor" href="#the-vectorized-score-s_2-and-matrix-algebra"></a>
</h2>
<p>Recall the mean-score approximation that leads to the estimating
equation used to solve for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
(cf.¬†equation (13) in the notes):
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><msup><mover><mi>œï</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>,</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo minsize="1.8" maxsize="1.8" stretchy="false" form="prefix">[</mo><msub><mi>Œ¥</mi><mi>r</mi></msub><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><msub><mi>Œ¥</mi><mi>r</mi></msub><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>r</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>Œ¥</mi><mi>r</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><msub><mover><mi>E</mi><mo accent="true">ÃÉ</mo></mover><mn>0</mn></msub><mo stretchy="false" form="prefix">{</mo><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><mi>Œ¥</mi><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚à£</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>;</mo><msup><mover><mi>œï</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>,</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="false" form="postfix">}</mo><mo minsize="1.8" maxsize="1.8" stretchy="false" form="postfix">]</mo><mo>=</mo><mn>0</mn><mi>.</mi></mrow><annotation encoding="application/x-tex">
S_2(\phi; \hat\phi^{(t)}, \hat\gamma) = \sum_{r=1}^n \Big[ \delta_r s(\phi;\delta_r, x^{\text{miss}}_r, x^{\text{out}}_r, y_r) + (1-\delta_r)\widetilde{E}_0\{ s(\phi;\delta, x^{\text{miss}}_r, x^{\text{out}}_r, Y) \mid x^{\text{out}}_r;\hat\phi^{(t)},\hat\gamma\} \Big] = 0.
</annotation></semantics></math></p>
<p>It is convenient to decompose this as the sum of observed and
unobserved contributions:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>S</mi><mtext mathvariant="normal">obs</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>S</mi><mtext mathvariant="normal">un</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
S_2(\phi) = S_{\text{obs}}(\phi) + S_{\text{un}}(\phi),
</annotation></semantics></math> where
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mtext mathvariant="normal">obs</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><mo>‚àë</mo><mrow><mi>r</mi><mo>:</mo><mspace width="0.167em"></mspace><msub><mi>Œ¥</mi><mi>r</mi></msub><mo>=</mo><mn>1</mn></mrow></munder><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><mi>Œ¥</mi><mo>=</mo><mn>1</mn><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>r</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
S_{\text{obs}}(\phi) = \sum_{r:\,\delta_r=1} s(\phi;\delta=1, x^{\text{miss}}_r, x^{\text{out}}_r, y_r)
</annotation></semantics></math> is the score contribution from
respondents, and the missing-unit contribution is approximated by the
discrete-support expectation
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mtext mathvariant="normal">un</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚âà</mo><munder><mo>‚àë</mo><mrow><mi>i</mi><mo>:</mo><mspace width="0.167em"></mspace><msub><mi>Œ¥</mi><mi>i</mi></msub><mo>=</mo><mn>0</mn></mrow></munder><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>1</mn></msub></munderover><msub><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><mi>Œ¥</mi><mo>=</mo><mn>0</mn><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
S_{\text{un}}(\phi) \approx \sum_{i:\,\delta_i=0} \sum_{j=1}^{n_1} W_{ij}(\phi)\, s(\phi;\delta=0, x^{\text{miss}}_i, x^{\text{out}}_i, y_j).
</annotation></semantics></math> The remainder of this section explains
how the double sum in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mtext mathvariant="normal">un</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S_{\text{un}}(\phi)</annotation></semantics></math>
is computed via matrix operations.</p>
<p>The crucial observation for vectorization is that the inner
conditional expectation for a non-respondent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
is approximated by a weighted finite-sum over the respondent support
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{y_j\}</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>E</mi><mo accent="true">ÃÉ</mo></mover><mn>0</mn></msub><mo stretchy="false" form="prefix">{</mo><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><mi>Œ¥</mi><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚à£</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">out</mtext></msubsup><mo stretchy="false" form="postfix">}</mo><mo>‚âà</mo><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>1</mn></msub></munderover><msub><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><mi>Œ¥</mi><mo>=</mo><mn>0</mn><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\widetilde{E}_0\{ s(\phi;\delta, x^{\text{miss}}_i, x^{\text{out}}_i, Y) \mid x^{\text{out}}_i\} \approx \sum_{j=1}^{n_1} W_{ij}(\phi)\, s(\phi;\delta=0, x^{\text{miss}}_i, x^{\text{out}}_i, y_j).
</annotation></semantics></math></p>
<p>Stacking the non-respondent expectations across all non-respondents
gives a single matrix operation. Let</p>
<ul>
<li><p>For each pair
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math>
evaluate the vector-valued score s at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ¥</mi><mo>=</mo><mn>0</mn><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\delta=0, x^{\text{miss}}_i, x^{\text{out}}_i, y_j)</annotation></semantics></math>.
Collect these quickly by exploiting the algebraic factorization of the
score (see the <code>s_function</code> implementation): many
parameter-specific components are separable in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
which allows creation of low-memory representations.</p></li>
<li><p>Denote by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>S</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><annotation encoding="application/x-tex">S^{(0)}_{ij}</annotation></semantics></math>
the p-dimensional score vector at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math>.
Organize these so that for each parameter index
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
we have an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0\times n_1</annotation></semantics></math>
matrix of values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">[</mo><msubsup><mi>S</mi><mrow><mo>‚Ä¢</mo><mo>‚Ä¢</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">]</mo></mrow><mi>m</mi></msub><annotation encoding="application/x-tex">[S^{(0)}_{\bullet\bullet}]_{m}</annotation></semantics></math>
(parameter-wise maps). Then the non-respondent contribution to the
overall score vector is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>0</mn></msub></munderover><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>1</mn></msub></munderover><msub><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><msubsup><mi>S</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">[</mo><mspace width="0.167em"></mspace><mtext mathvariant="normal">vec</mtext><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">(</mo><mi>W</mi><mo>‚àò</mo><msub><mrow><mo stretchy="true" form="prefix">[</mo><msup><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">]</mo></mrow><mn>1</mn></msub><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mo>,</mo><mspace width="0.167em"></mspace><mi>‚Ä¶</mi><mspace width="0.167em"></mspace><mo>,</mo><mspace width="0.167em"></mspace><mtext mathvariant="normal">vec</mtext><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">(</mo><mi>W</mi><mo>‚àò</mo><msub><mrow><mo stretchy="true" form="prefix">[</mo><msup><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">]</mo></mrow><mi>p</mi></msub><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">)</mo><mspace width="0.167em"></mspace><mo stretchy="true" form="postfix">]</mo></mrow><mi>‚ä§</mi></msup></mrow><annotation encoding="application/x-tex">
\sum_{i=1}^{n_0} \sum_{j=1}^{n_1} W_{ij}(\phi)\, S^{(0)}_{ij} = \left[ \,\text{vec}
\big( W \circ [S^{(0)}]_{1} \big)\, ,\, \ldots\, ,\, \text{vec}\big( W \circ [S^{(0)}]_{p} \big)\,\right]^\top
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>‚àò</mo><annotation encoding="application/x-tex">\circ</annotation></semantics></math>
denotes elementwise multiplication and <code>vec</code> followed by an
appropriate collapse (row-sum or column-sum) implements the inner
summation depending on the parameter‚Äôs factorization. In concrete
computational terms:</p></li>
<li><p>For parameter components that multiply per-row (i.e.¬†depend only
on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
times a factor that is a function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>j</mi></msub><annotation encoding="application/x-tex">y_j</annotation></semantics></math>)
we compute elementwise products between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math>
and a factor matrix and then row-sum across
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
to get an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n_0\times 1</annotation></semantics></math>
contribution per non-respondent, and then sum across
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>.</p></li>
<li><p>For intercept-like or column-wise components, a column-sum
followed by weighted multiplication suffices.</p></li>
</ul>
<p>In the implementation this reduces to a sequence of dense matrix
operations and row/column sums rather than explicit loops over the
expanded index set of length
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0\times n_1</annotation></semantics></math>.
This yields large speed and memory benefits for real datasets.</p>
<p>Concise vectorized S_2 recipe (conceptual):</p>
<ol style="list-style-type: decimal">
<li>Build
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>
(size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0\times n_1</annotation></semantics></math>)
via <code>generate_conditional_density_matrix(model)</code>.</li>
<li>Build
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
(size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>1</mn></msub><annotation encoding="application/x-tex">n_1</annotation></semantics></math>)
via <code>generate_C_matrix(model)</code> by summing the conditional
densities over respondents.</li>
<li>For a candidate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(\phi)</annotation></semantics></math>
(size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0\times n_1</annotation></semantics></math>)
via <code>generate_Odds(model,\phi)</code>.</li>
<li>Form
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac displaystyle="true"><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àò</mo><mi>F</mi></mrow><mrow><msub><mn>ùüè</mn><msub><mi>n</mi><mn>0</mn></msub></msub><msup><mi>C</mi><mi>‚ä§</mi></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">W(\phi)=\dfrac{O(\phi)\circ F}{\mathbf{1}_{n_0} C^\top}</annotation></semantics></math>
(i.e.¬†divide each column of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo>‚àò</mo><mi>F</mi></mrow><annotation encoding="application/x-tex">O\circ F</annotation></semantics></math>
by the corresponding scalar
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>C</mi><mi>j</mi></msub><annotation encoding="application/x-tex">C_j</annotation></semantics></math>).</li>
<li>Compute observed-score sum:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mtext mathvariant="normal">obs</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mo>‚àë</mo><mrow><mi>r</mi><mo>:</mo><mspace width="0.167em"></mspace><msub><mi>Œ¥</mi><mi>r</mi></msub><mo>=</mo><mn>1</mn></mrow></msub><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><mi>Œ¥</mi><mo>=</mo><mn>1</mn><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>r</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>r</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S_{\text{obs}}(\phi)=\sum_{r:\,\delta_r=1} s(\phi;\delta=1,x^{\text{miss}}_r,x^{\text{out}}_r,y_r)</annotation></semantics></math>
(this is small: one score vector per respondent).</li>
<li>Compute non-respondent expected-score: use
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">W(\phi)</annotation></semantics></math>
and parameter-wise factor matrices derived from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚ãÖ</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">s(\cdot)</annotation></semantics></math>
to compute
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mtext mathvariant="normal">un</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>0</mn></msub></munderover><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>1</mn></msub></munderover><msub><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>;</mo><mi>Œ¥</mi><mo>=</mo><mn>0</mn><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mtext mathvariant="normal">out</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S_{\text{un}}(\phi)=\sum_{i=1}^{n_0}\sum_{j=1}^{n_1} W_{ij}(\phi)\, s(\phi;\delta=0,x^{\text{miss}}_i,x^{\text{out}}_i,y_j)</annotation></semantics></math>
implemented via matrix multiplications and row/column sums.</li>
<li>Return the total score
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>S</mi><mtext mathvariant="normal">obs</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>S</mi><mtext mathvariant="normal">un</mtext></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S_2(\phi)=S_{\text{obs}}(\phi) + S_{\text{un}}(\phi)</annotation></semantics></math>.</li>
</ol>
<p>The root-finder then searches for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">S_2(\phi)=0</annotation></semantics></math>.
In the package this is implemented by repeatedly forming
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(\phi)</annotation></semantics></math>
for the current candidate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>,
computing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">W(\phi)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S_2(\phi)</annotation></semantics></math>,
and letting <code>nleqslv</code> perform the iteration.</p>
</div>
<div class="section level2">
<h2 id="mean-estimation-and-survey-weights">Mean estimation and survey weights<a class="anchor" aria-label="anchor" href="#mean-estimation-and-survey-weights"></a>
</h2>
<p>After the response-model parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>œï</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\phi</annotation></semantics></math>
are obtained the package reports a mean estimate of the target outcome
using an inverse-probability reweighting form. Let respondents be
indexed by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">j=1,\dots,n_1</annotation></semantics></math>;
denote by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÄ</mi><mi>j</mi></msub><mo>=</mo><mi>œÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>x</mi><mi>j</mi><mtext mathvariant="normal">miss</mtext></msubsup><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo>;</mo><mover><mi>œï</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi_j = \pi(x^{\text{miss}}_j,y_j;\hat\phi)</annotation></semantics></math>
the fitted response probabilities evaluated at each respondent (here we
write
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>x</mi><mi>j</mi><mtext mathvariant="normal">miss</mtext></msubsup><annotation encoding="application/x-tex">x^{\text{miss}}_j</annotation></semantics></math>
for the covariates used in the missingness model evaluated at respondent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>).
With design weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>j</mi></msub><annotation encoding="application/x-tex">w_j</annotation></semantics></math>
(by default
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>‚â°</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">w_j\equiv 1</annotation></semantics></math>
for non-survey data) the point estimator computed in the implementation
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Œº</mi><mo accent="true">ÃÇ</mo></mover><mo>=</mo><mfrac><mrow><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>1</mn></msub></munderover><msub><mi>w</mi><mi>j</mi></msub><mspace width="0.167em"></mspace><msub><mi>y</mi><mi>j</mi></msub><mi>/</mi><msub><mi>œÄ</mi><mi>j</mi></msub></mrow><mrow><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>1</mn></msub></munderover><msub><mi>w</mi><mi>j</mi></msub><mi>/</mi><msub><mi>œÄ</mi><mi>j</mi></msub></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
\hat\mu = \frac{\sum_{j=1}^{n_1} w_j\, y_j / \pi_j}{\sum_{j=1}^{n_1} w_j / \pi_j}.\tag{mean-est}
</annotation></semantics></math></p>
<p>Notes on survey weights and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mn>1</mn></msub><annotation encoding="application/x-tex">f_1</annotation></semantics></math>
fitting:</p>
<ul>
<li>The conditional-density fit used to build
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>
can incorporate respondent sampling weights when provided (the
implementation passes respondent weights to the density-fitting
routine). Thus
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚ãÖ</mo><mo>‚à£</mo><mi>x</mi><mo>;</mo><mi>Œ≥</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_1(\cdot\mid x;\gamma)</annotation></semantics></math>
may be a weighted fit when <code>design_weights</code> or a survey
<code>design</code> is supplied.</li>
<li>The mean-estimate (mean-est) also uses design weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>j</mi></msub><annotation encoding="application/x-tex">w_j</annotation></semantics></math>
in both numerator and denominator as shown above. In code these are
provided via <code>model$design_weights</code> and default to 1 for
non-survey use.</li>
</ul>
<p>In short: survey weights enter two places ‚Äî (i) the
conditional-density estimation (if requested) and (ii) the final mean
calculation through the weighted IPW-type ratio in (mean-est).</p>
</div>
<div class="section level2">
<h2 id="arguments-passed-to-exptilt-summary">Arguments passed to <code>exptilt</code> (summary)<a class="anchor" aria-label="anchor" href="#arguments-passed-to-exptilt-summary"></a>
</h2>
<p>The <code>exptilt</code> / <code>exptilt.data.frame</code>
user-facing function accepts a number of arguments that control model
specification and computation; the most important are:</p>
<ul>
<li>
<code>data</code>: a <code>data.frame</code> with outcome and
covariates.</li>
<li>
<code>formula</code>: a partitioned formula of the form
<code>y ~ aux1 + aux2 | miss1 + miss2</code> where the left part (before
<code>|</code>) lists <code>covariates_for_outcome</code> and the right
part lists <code>covariates_for_missingness</code> (the package helper
splits these automatically).</li>
<li>
<code>auxiliary_means</code>: (optional) population or target means
for auxiliary variables used for scaling.</li>
<li>
<code>standardize</code>: logical, whether to standardize features
before fitting.</li>
<li>
<code>prob_model_type</code>: character, either <code>"logit"</code>
or <code>"probit"</code> to select the response probability family.</li>
<li>
<code>y_dens</code>: choice of conditional-density family;
<code>"auto"</code>, <code>"normal"</code>, <code>"lognormal"</code>, or
<code>"exponential"</code>.</li>
<li>
<code>variance_method</code>: <code>"delta"</code> or
<code>"bootstrap"</code> for variance estimation.</li>
<li>
<code>bootstrap_reps</code>: number of bootstrap replications when
bootstrap is used.</li>
<li>
<code>control</code>: list of control parameters forwarded to the
nonlinear solver (<code>nleqslv</code>).</li>
<li>
<code>stopping_threshold</code>: numeric; the sup-norm threshold for
early stopping of the score (see above).</li>
<li>
<code>on_failure</code>: behavior on failure (<code>"return"</code>
or <code>"error"</code>).</li>
<li>
<code>supress_warnings</code>: logical to silence certain
warnings.</li>
<li>
<code>design_weights</code>: optional vector of respondent design
weights (or full-sample weights which are subset internally).</li>
<li>
<code>survey_design</code>: optional <code>survey.design</code>
object; when provided some internal logic uses the survey path.</li>
<li>
<code>trace_level</code>: integer controlling verbosity.</li>
<li>
<code>sample_size</code>: integer for stratified subsampling used
when data are large.</li>
<li>
<code>outcome_label</code>, <code>user_formula</code>: utility
arguments used for presentation and bookkeeping.</li>
</ul>
<p>These arguments appear in the <code>exptilt.data.frame</code>
function signature and control how the matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>O</mi><annotation encoding="application/x-tex">O</annotation></semantics></math>
are built and how the solver is run.</p>
</div>
<div class="section level2">
<h2 id="connection-to-the-em-viewpoint">Connection to the EM viewpoint<a class="anchor" aria-label="anchor" href="#connection-to-the-em-viewpoint"></a>
</h2>
<p>The EM-like update displayed in the theoretical notes (equation (14))
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>œï</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>‚Üê</mo><mrow><mtext mathvariant="normal">solve </mtext><mspace width="0.333em"></mspace></mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo>‚à£</mo><msup><mover><mi>œï</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>,</mo><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\hat\phi^{(t+1)} \leftarrow \text{solve } S_2(\phi \mid \hat\phi^{(t)},\hat\gamma)=0</annotation></semantics></math>
is exactly what the implementation achieves: for a fixed
conditional-density estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>Œ≥</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat\gamma</annotation></semantics></math>
and a current
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>œï</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\hat\phi^{(t)}</annotation></semantics></math>,
the expectations for the missing units are approximated by the discrete
support on observed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>j</mi></msub><annotation encoding="application/x-tex">y_j</annotation></semantics></math>
and the resulting equation for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
is solved (via root-finding). The heavy-lift is performed by the matrix
calculus described earlier ‚Äî constructing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>O</mi><annotation encoding="application/x-tex">O</annotation></semantics></math>
and then computing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math>
and multiplying by the parameter-wise score factors.</p>
</div>
<div class="section level2">
<h2 id="stopping-criterion-maximum-norm">Stopping criterion (maximum-norm)<a class="anchor" aria-label="anchor" href="#stopping-criterion-maximum-norm"></a>
</h2>
<p>Practical optimization requires a convergence criterion. The
implementation uses the maximum absolute component of the vector-valued
score as a stopping rule. Concretely, if the solver produces a score
vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S_2(\phi)</annotation></semantics></math>
with
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>max</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>p</mi></mrow></munder><mrow><mo stretchy="true" form="prefix">|</mo><msub><mi>S</mi><mrow><mn>2</mn><mo>,</mo><mi>m</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">|</mo></mrow><mo>&lt;</mo><mi>Œµ</mi></mrow><annotation encoding="application/x-tex">\max_{m=1,\dots,p} |S_{2,m}(\phi)| &lt; \varepsilon</annotation></semantics></math>
for a user-specified <code>stopping_threshold = \varepsilon</code>, the
algorithm treats this as converged. In the code this is used as an
early-exit inside the target-function passed to the nonlinear solver:
when the score‚Äôs sup-norm is below the threshold, a zero vector is
returned to signal convergence and avoid further unnecessary
computations.</p>
<p>This choice matches the intuition that the root-finder should stop
when the estimating equations are (componentwise) negligibly small.</p>
</div>
<div class="section level2">
<h2 id="practical-tutorial-from-raw-data-to-matrix-operations-conceptual-steps">Practical tutorial: from raw data to matrix operations (conceptual
steps)<a class="anchor" aria-label="anchor" href="#practical-tutorial-from-raw-data-to-matrix-operations-conceptual-steps"></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Fit the conditional density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>‚à£</mo><mi>x</mi><mo>;</mo><mi>Œ≥</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_1(y\mid x;\gamma)</annotation></semantics></math>
using respondents and <code>covariates_for_outcome</code>. This gives a
function that evaluates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_1(y, x)</annotation></semantics></math>
for any
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
and any covariate row
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
(used for both respondents and non-respondents).</p></li>
<li><p>Evaluate the conditional density at the Cartesian product of
non-respondent covariates and observed respondent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
values to form
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>
(done by <code>generate_conditional_density_matrix</code>). This is the
empirical imputation support. Think of rows as target non-respondents
and columns as candidate respondent outcomes.</p></li>
<li><p>Evaluate the same conditional density at respondent covariates to
form the column-normalizer
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
(done by <code>generate_C_matrix</code>) ‚Äî this is simply the column-sum
of densities over respondents.</p></li>
<li><p>For each trial value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
of the response-model parameters, compute the odds matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(\phi)</annotation></semantics></math>
using the separable linear predictor and link function (implemented
efficiently via <code><a href="https://rdrr.io/r/base/outer.html" class="external-link">outer()</a></code> in code). Combine
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>O</mi><annotation encoding="application/x-tex">O</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>
and normalize columns by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
to obtain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">W(\phi)</annotation></semantics></math>.</p></li>
<li><p>Use the vectorized <code>s_function</code> to obtain
parameter-specific factor matrices for the non-respondent-imputed
scores; multiply (elementwise) by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">W(\phi)</annotation></semantics></math>
and reduce (row/column sums) to compute the non-respondent contribution
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S_2(\phi)</annotation></semantics></math>.</p></li>
<li><p>Add the observed-respondent score and use a root-finder
(e.g.¬†<code>nleqslv</code>) to find
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">S_2(\phi)=0</annotation></semantics></math>.
The solver may use the maximum-norm stopping threshold described above
to exit early.</p></li>
</ol>
</div>
<div class="section level2">
<h2 id="why-the-vectorization-matters-practical-remarks">Why the vectorization matters (practical remarks)<a class="anchor" aria-label="anchor" href="#why-the-vectorization-matters-practical-remarks"></a>
</h2>
<ul>
<li>Memory: the naive expansion to an explicit dataset of size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>0</mn></msub><mo>√ó</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">n_0\times n_1</annotation></semantics></math>
would store duplicated covariate rows and blow up memory. The
implemention exploits separability (intercept +
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>X</mi><mi>i</mi><mtext mathvariant="normal">miss</mtext></msubsup><msub><mi>Œ≤</mi><mtext mathvariant="normal">miss</mtext></msub></mrow><annotation encoding="application/x-tex">X^{\text{miss}}_i\beta_{\text{miss}}</annotation></semantics></math>
+
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>y</mi></msub><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_y y_j</annotation></semantics></math>)
and vectorized R primitives (<code>outer</code>, matrix multiplications,
column/row sums) to avoid large temporary allocations.</li>
<li>Speed: elementwise operations on dense matrices plus
BLAS-accelerated matrix multiplication are much faster than interpreted
loops in R for typical dataset sizes.</li>
<li>Clarity: organizing logic as the three matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>O</mi><annotation encoding="application/x-tex">O</annotation></semantics></math>,
followed by elementwise combination and reductions, makes the
relationship between the statistical approximation and the
implementation transparent and easier to reason about.</li>
</ul>
</div>
<div class="section level2">
<h2 id="closing-notes-and-references">Closing notes and references<a class="anchor" aria-label="anchor" href="#closing-notes-and-references"></a>
</h2>
<p>This vignette mapped the implementation functions to the math in the
theoretical notes and showed how the EM-like mean-score step reduces to
a small set of matrix operations. The implementation follows the ideas
described in Riddles et al.¬†(2016) for exponential tilting under NMAR:
fit the conditional density on respondents, approximate the missing-data
expectation by a finite sum over observed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
values, and solve the resulting estimating equations for the
missingness-model parameters.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Maciej Beresewicz, Igor Ko≈Çodziej, Mateusz Iwaniuk.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
